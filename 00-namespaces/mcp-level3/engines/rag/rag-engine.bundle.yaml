# MCP Level 3 - RAG Engine Bundle
# Defines component inventory, deployment configuration, and resource management

apiVersion: mcp.ninjatech.ai/v1alpha1
kind: EngineBundle
metadata:
  name: rag-engine
  namespace: mcp-level3
  version: 1.0.0
  description: "RAG Engine deployment bundle with all components and configurations"
  labels:
    engine-type: rag
    deployment-tier: core
    criticality: high
  annotations:
    mcp.ninjatech.ai/bundle-version: "1.0.0"
    mcp.ninjatech.ai/last-updated: "2024-01-11"

# ============================================================================
# COMPONENT INVENTORY
# ============================================================================

components:
  # Core Services
  services:
    - name: rag-api-service
      type: rest-api
      version: 1.0.0
      description: "REST API service for RAG operations"
      image: "ninjatech/rag-api:1.0.0"
      port: 8080
      replicas: 3
      resources:
        requests:
          cpu: "500m"
          memory: "1Gi"
        limits:
          cpu: "2000m"
          memory: "4Gi"
      health_check:
        path: "/health"
        interval: 10s
        timeout: 5s
    
    - name: rag-grpc-service
      type: grpc
      version: 1.0.0
      description: "gRPC service for high-performance RAG operations"
      image: "ninjatech/rag-grpc:1.0.0"
      port: 9090
      replicas: 3
      resources:
        requests:
          cpu: "1000m"
          memory: "2Gi"
        limits:
          cpu: "4000m"
          memory: "8Gi"
    
    - name: vector-retrieval-service
      type: microservice
      version: 1.0.0
      description: "Vector similarity search service"
      image: "ninjatech/vector-retrieval:1.0.0"
      port: 8081
      replicas: 5
      resources:
        requests:
          cpu: "1000m"
          memory: "2Gi"
        limits:
          cpu: "4000m"
          memory: "8Gi"
    
    - name: graph-retrieval-service
      type: microservice
      version: 1.0.0
      description: "Knowledge graph traversal service"
      image: "ninjatech/graph-retrieval:1.0.0"
      port: 8082
      replicas: 3
      resources:
        requests:
          cpu: "500m"
          memory: "1Gi"
        limits:
          cpu: "2000m"
          memory: "4Gi"
    
    - name: answer-generation-service
      type: microservice
      version: 1.0.0
      description: "LLM-based answer generation service"
      image: "ninjatech/answer-generation:1.0.0"
      port: 8083
      replicas: 5
      resources:
        requests:
          cpu: "2000m"
          memory: "4Gi"
          gpu: "1"
        limits:
          cpu: "8000m"
          memory: "16Gi"
          gpu: "2"
    
    - name: indexing-service
      type: batch-processor
      version: 1.0.0
      description: "Document indexing and chunking service"
      image: "ninjatech/indexing:1.0.0"
      port: 8084
      replicas: 2
      resources:
        requests:
          cpu: "1000m"
          memory: "2Gi"
        limits:
          cpu: "4000m"
          memory: "8Gi"
  
  # Data Stores
  datastores:
    - name: vector-database
      type: vector-db
      provider: "pinecone"
      version: "latest"
      configuration:
        dimension: 1536
        metric: "cosine"
        replicas: 3
        shards: 4
      resources:
        storage: "500Gi"
        iops: 10000
    
    - name: graph-database
      type: graph-db
      provider: "neo4j"
      version: "5.x"
      configuration:
        replicas: 3
        cluster_mode: true
      resources:
        storage: "1Ti"
        memory: "32Gi"
    
    - name: metadata-store
      type: relational-db
      provider: "postgresql"
      version: "15.x"
      configuration:
        replicas: 3
        max_connections: 1000
      resources:
        storage: "200Gi"
        memory: "16Gi"
    
    - name: cache-store
      type: cache
      provider: "redis"
      version: "7.x"
      configuration:
        replicas: 3
        cluster_mode: true
      resources:
        memory: "32Gi"
  
  # Libraries and SDKs
  libraries:
    - name: rag-client-sdk
      type: sdk
      language: python
      version: 1.0.0
      repository: "https://github.com/ninjatech/rag-client-sdk"
    
    - name: rag-client-sdk-js
      type: sdk
      language: javascript
      version: 1.0.0
      repository: "https://github.com/ninjatech/rag-client-sdk-js"
    
    - name: embedding-library
      type: library
      language: python
      version: 1.0.0
      dependencies:
        - "transformers>=4.30.0"
        - "sentence-transformers>=2.2.0"
    
    - name: chunking-library
      type: library
      language: python
      version: 1.0.0
      dependencies:
        - "langchain>=0.1.0"
        - "tiktoken>=0.5.0"
  
  # External Integrations
  integrations:
    - name: llm-service
      type: external-api
      provider: "openai"
      endpoint: "https://api.openai.com/v1"
      models:
        - "gpt-4"
        - "gpt-3.5-turbo"
        - "text-embedding-ada-002"
    
    - name: monitoring-service
      type: observability
      provider: "datadog"
      endpoint: "https://api.datadoghq.com"
    
    - name: logging-service
      type: logging
      provider: "elasticsearch"
      endpoint: "https://logs.ninjatech.ai"

# ============================================================================
# DEPLOYMENT CONFIGURATION
# ============================================================================

deployment:
  # Deployment Strategy
  strategy:
    type: "rolling"
    rolling_update:
      max_surge: 1
      max_unavailable: 0
    canary:
      enabled: true
      steps:
        - weight: 10
          pause: 300s
        - weight: 50
          pause: 600s
        - weight: 100
  
  # Scaling Configuration
  scaling:
    horizontal:
      enabled: true
      min_replicas: 3
      max_replicas: 20
      metrics:
        - type: cpu
          target: 70
        - type: memory
          target: 80
        - type: custom
          name: requests_per_second
          target: 1000
    
    vertical:
      enabled: true
      mode: "auto"
      update_policy: "off"
  
  # Resource Quotas
  quotas:
    cpu: "100"
    memory: "200Gi"
    storage: "2Ti"
    gpu: "10"
  
  # Network Configuration
  network:
    service_mesh:
      enabled: true
      provider: "istio"
      mtls: true
    
    ingress:
      enabled: true
      class: "nginx"
      annotations:
        cert-manager.io/cluster-issuer: "letsencrypt-prod"
      rules:
        - host: "rag.ninjatech.ai"
          paths:
            - path: "/"
              service: rag-api-service
              port: 8080
    
    egress:
      enabled: true
      allowed_destinations:
        - "api.openai.com"
        - "*.pinecone.io"
        - "*.neo4j.io"

# ============================================================================
# ENVIRONMENT CONFIGURATION
# ============================================================================

environments:
  development:
    replicas: 1
    resources:
      cpu: "2"
      memory: "4Gi"
    features:
      debug: true
      profiling: true
  
  staging:
    replicas: 2
    resources:
      cpu: "10"
      memory: "20Gi"
    features:
      debug: false
      profiling: true
  
  production:
    replicas: 3
    resources:
      cpu: "100"
      memory: "200Gi"
    features:
      debug: false
      profiling: false
      high_availability: true

# ============================================================================
# SECRETS AND CONFIGURATION
# ============================================================================

secrets:
  - name: openai-api-key
    type: api-key
    provider: vault
    path: "secret/rag/openai"
  
  - name: vector-db-credentials
    type: credentials
    provider: vault
    path: "secret/rag/vector-db"
  
  - name: graph-db-credentials
    type: credentials
    provider: vault
    path: "secret/rag/graph-db"
  
  - name: tls-certificates
    type: certificate
    provider: cert-manager
    issuer: letsencrypt-prod

config_maps:
  - name: rag-config
    data:
      embedding_model: "text-embedding-ada-002"
      chunk_size: "1000"
      chunk_overlap: "200"
      top_k: "10"
      temperature: "0.7"
  
  - name: logging-config
    data:
      log_level: "info"
      log_format: "json"
      log_output: "stdout"

# ============================================================================
# HEALTH CHECKS AND PROBES
# ============================================================================

health_checks:
  liveness:
    http_get:
      path: "/health/live"
      port: 8080
    initial_delay: 30s
    period: 10s
    timeout: 5s
    failure_threshold: 3
  
  readiness:
    http_get:
      path: "/health/ready"
      port: 8080
    initial_delay: 10s
    period: 5s
    timeout: 3s
    failure_threshold: 3
  
  startup:
    http_get:
      path: "/health/startup"
      port: 8080
    initial_delay: 0s
    period: 10s
    timeout: 5s
    failure_threshold: 30

# ============================================================================
# MONITORING AND OBSERVABILITY
# ============================================================================

observability:
  # Metrics
  metrics:
    enabled: true
    provider: prometheus
    port: 9090
    path: "/metrics"
    scrape_interval: 15s
    
    custom_metrics:
      - name: rag_retrieval_latency
        type: histogram
        buckets: [0.1, 0.5, 1, 2, 5]
      
      - name: rag_generation_latency
        type: histogram
        buckets: [1, 5, 10, 30, 60]
      
      - name: rag_requests_total
        type: counter
      
      - name: rag_errors_total
        type: counter
  
  # Logging
  logging:
    enabled: true
    provider: elasticsearch
    level: info
    format: json
    
    structured_logging:
      enabled: true
      fields:
        - request_id
        - user_id
        - query
        - latency
        - status
  
  # Tracing
  tracing:
    enabled: true
    provider: jaeger
    sampling_rate: 0.1
    
    spans:
      - retrieval
      - generation
      - indexing
  
  # Alerting
  alerting:
    enabled: true
    provider: alertmanager
    
    rules:
      - name: high_error_rate
        condition: "rate(rag_errors_total[5m]) > 0.05"
        severity: critical
        notification: ["pagerduty", "slack"]
      
      - name: high_latency
        condition: "histogram_quantile(0.95, rag_retrieval_latency) > 1"
        severity: warning
        notification: ["slack"]

# ============================================================================
# SECURITY CONFIGURATION
# ============================================================================

security:
  # Pod Security
  pod_security:
    run_as_non_root: true
    run_as_user: 1000
    fs_group: 2000
    read_only_root_filesystem: true
  
  # Network Policies
  network_policies:
    - name: allow-ingress
      ingress:
        - from:
            - namespace_selector:
                match_labels:
                  name: ingress-nginx
    
    - name: allow-egress
      egress:
        - to:
            - namespace_selector:
                match_labels:
                  name: vector-db
        - to:
            - namespace_selector:
                match_labels:
                  name: graph-db
  
  # Service Account
  service_account:
    name: rag-engine-sa
    automount_token: true
    
    rbac:
      - api_groups: [""]
        resources: ["secrets", "configmaps"]
        verbs: ["get", "list"]

# ============================================================================
# BACKUP AND DISASTER RECOVERY
# ============================================================================

backup:
  enabled: true
  schedule: "0 2 * * *"  # Daily at 2 AM
  retention: 30d
  
  targets:
    - vector-database
    - graph-database
    - metadata-store
  
  storage:
    provider: s3
    bucket: "rag-backups"
    region: "us-east-1"

disaster_recovery:
  rpo: 1h  # Recovery Point Objective
  rto: 4h  # Recovery Time Objective
  
  failover:
    enabled: true
    regions:
      - primary: us-east-1
        secondary: us-west-2

# ============================================================================
# DOCUMENTATION
# ============================================================================

documentation:
  deployment_guide: "https://docs.ninjatech.ai/mcp/rag-engine/deployment"
  operations_manual: "https://docs.ninjatech.ai/mcp/rag-engine/operations"
  troubleshooting: "https://docs.ninjatech.ai/mcp/rag-engine/troubleshooting"