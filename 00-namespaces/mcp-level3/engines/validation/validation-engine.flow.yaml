# MCP Level 3 - Validation Engine Flow Definitions

apiVersion: mcp.ninjatech.ai/v1alpha1
kind: EngineFlow
metadata:
  name: validation-engine
  namespace: mcp-level3
  version: 1.0.0
  description: "Validation Engine workflow definitions"
  labels:
    engine-type: validation
    flow-type: orchestration

workflows:
  # Data Validation Workflow
  - name: data-validation
    description: "Validate data against schema and quality rules"
    type: sequential
    trigger:
      type: api
      endpoint: "/api/v1/validation/validate"
      method: POST
    
    input:
      schema:
        type: object
        required: [data, schema_id]
        properties:
          data:
            type: object
          schema_id:
            type: string
          quality_rules:
            type: array
    
    steps:
      - id: fetch-schema
        name: "Fetch Schema"
        type: service-call
        service: schema-registry
        action: get
        input:
          schema_id: "{{workflow.input.schema_id}}"
        output:
          schema: "{{step.result.schema}}"
        timeout: 2s
      
      - id: validate-schema
        name: "Validate Against Schema"
        type: service-call
        service: schema-validator
        action: validate
        input:
          data: "{{workflow.input.data}}"
          schema: "{{steps.fetch-schema.output.schema}}"
        output:
          schema_valid: "{{step.result.valid}}"
          schema_errors: "{{step.result.errors}}"
        timeout: 5s
      
      - id: validate-quality
        name: "Validate Data Quality"
        type: conditional
        condition: "{{steps.validate-schema.output.schema_valid == true}}"
        then:
          - type: service-call
            service: quality-validator
            action: validate
            input:
              data: "{{workflow.input.data}}"
              rules: "{{workflow.input.quality_rules}}"
            output:
              quality_valid: "{{step.result.valid}}"
              quality_violations: "{{step.result.violations}}"
        timeout: 10s
      
      - id: calculate-score
        name: "Calculate Quality Score"
        type: service-call
        service: quality-validator
        action: calculate_score
        input:
          schema_valid: "{{steps.validate-schema.output.schema_valid}}"
          quality_violations: "{{steps.validate-quality.output.quality_violations}}"
        output:
          quality_score: "{{step.result.score}}"
        timeout: 2s
      
      - id: generate-report
        name: "Generate Validation Report"
        type: service-call
        service: validation-api-service
        action: generate_report
        input:
          schema_valid: "{{steps.validate-schema.output.schema_valid}}"
          schema_errors: "{{steps.validate-schema.output.schema_errors}}"
          quality_valid: "{{steps.validate-quality.output.quality_valid}}"
          quality_violations: "{{steps.validate-quality.output.quality_violations}}"
          quality_score: "{{steps.calculate-score.output.quality_score}}"
        output:
          report_id: "{{step.result.id}}"
        timeout: 5s
    
    output:
      schema:
        type: object
        properties:
          valid:
            type: boolean
          report_id:
            type: string
          quality_score:
            type: number

  # Test Execution Workflow
  - name: test-execution
    description: "Execute test suite"
    type: sequential
    trigger:
      type: api
      endpoint: "/api/v1/validation/tests/{test_id}/execute"
      method: POST
    
    input:
      schema:
        type: object
        required: [test_id]
        properties:
          test_id:
            type: string
          environment:
            type: string
    
    steps:
      - id: fetch-test-case
        name: "Fetch Test Case"
        type: service-call
        service: test-runner
        action: get_test
        input:
          test_id: "{{workflow.input.test_id}}"
        output:
          test_case: "{{step.result.test}}"
        timeout: 5s
      
      - id: setup-environment
        name: "Setup Test Environment"
        type: service-call
        service: test-runner
        action: setup
        input:
          environment: "{{workflow.input.environment}}"
          test_case: "{{steps.fetch-test-case.output.test_case}}"
        output:
          environment_ready: "{{step.result.ready}}"
        timeout: 30s
      
      - id: execute-test
        name: "Execute Test"
        type: service-call
        service: test-runner
        action: execute
        input:
          test_case: "{{steps.fetch-test-case.output.test_case}}"
        output:
          test_result: "{{step.result}}"
        error_handling:
          on_error: continue
        timeout: 300s
      
      - id: collect-metrics
        name: "Collect Test Metrics"
        type: service-call
        service: evaluation-service
        action: collect_metrics
        input:
          test_result: "{{steps.execute-test.output.test_result}}"
        output:
          metrics: "{{step.result.metrics}}"
        timeout: 5s
      
      - id: store-results
        name: "Store Test Results"
        type: service-call
        service: test-results-store
        action: store
        input:
          test_id: "{{workflow.input.test_id}}"
          result: "{{steps.execute-test.output.test_result}}"
          metrics: "{{steps.collect-metrics.output.metrics}}"
        output:
          result_id: "{{step.result.id}}"
        timeout: 5s
      
      - id: cleanup-environment
        name: "Cleanup Test Environment"
        type: service-call
        service: test-runner
        action: cleanup
        input:
          environment: "{{workflow.input.environment}}"
        timeout: 30s
    
    output:
      schema:
        type: object
        properties:
          test_id:
            type: string
          status:
            type: string
          result_id:
            type: string

  # Model Evaluation Workflow
  - name: model-evaluation
    description: "Evaluate ML model performance"
    type: sequential
    trigger:
      type: api
      endpoint: "/api/v1/validation/evaluate"
      method: POST
    
    input:
      schema:
        type: object
        required: [predictions, ground_truth]
        properties:
          predictions:
            type: array
          ground_truth:
            type: array
          metrics:
            type: array
    
    steps:
      - id: validate-inputs
        name: "Validate Inputs"
        type: validation
        action: validate_evaluation_inputs
        input:
          predictions: "{{workflow.input.predictions}}"
          ground_truth: "{{workflow.input.ground_truth}}"
        timeout: 5s
      
      - id: calculate-metrics
        name: "Calculate Metrics"
        type: parallel
        branches:
          - id: accuracy
            steps:
              - type: service-call
                service: evaluation-service
                action: calculate_accuracy
                input:
                  predictions: "{{workflow.input.predictions}}"
                  ground_truth: "{{workflow.input.ground_truth}}"
                output:
                  accuracy: "{{step.result.value}}"
          
          - id: precision-recall
            steps:
              - type: service-call
                service: evaluation-service
                action: calculate_precision_recall
                input:
                  predictions: "{{workflow.input.predictions}}"
                  ground_truth: "{{workflow.input.ground_truth}}"
                output:
                  precision: "{{step.result.precision}}"
                  recall: "{{step.result.recall}}"
          
          - id: f1-score
            steps:
              - type: service-call
                service: evaluation-service
                action: calculate_f1
                input:
                  predictions: "{{workflow.input.predictions}}"
                  ground_truth: "{{workflow.input.ground_truth}}"
                output:
                  f1_score: "{{step.result.value}}"
        
        join:
          type: all
          timeout: 30s
      
      - id: generate-evaluation-report
        name: "Generate Evaluation Report"
        type: service-call
        service: evaluation-service
        action: generate_report
        input:
          metrics: "{{steps.calculate-metrics.output}}"
        output:
          report_id: "{{step.result.id}}"
        timeout: 10s
    
    output:
      schema:
        type: object
        properties:
          metrics:
            type: object
          report_id:
            type: string

error_handling:
  patterns:
    - name: validation-retry
      max_retries: 2
      backoff: linear

state_management:
  storage: redis
  ttl: 3600

monitoring:
  metrics:
    - name: validation_duration
      type: histogram
    - name: test_execution_duration
      type: histogram

documentation:
  workflow_guide: "https://docs.ninjatech.ai/mcp/validation-engine/workflows"
