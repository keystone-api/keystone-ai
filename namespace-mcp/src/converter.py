#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
MachineNativeOps å‘½åç©ºé–“ MCP è½‰æ›å™¨
ç‰ˆæœ¬: 1.0.0
æè¿°: å…­å±¤æ²»ç†å°é½Šçš„é–‹æºå°ˆæ¡ˆè‡ªå‹•è½‰æ›æ ¸å¿ƒå¼•æ“
"""

import os
import re
import json
import yaml
import hashlib
import logging
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
from datetime import datetime

# é…ç½®æ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger('MachineNativeOps.Converter')


@dataclass
class ConversionRule:
    """è½‰æ›è¦å‰‡æ•¸æ“šçµæ§‹"""
    name: str
    pattern: str
    replacement: str
    file_types: List[str]
    context: str
    priority: int
    description: str


@dataclass
class ConversionResult:
    """è½‰æ›çµæœæ•¸æ“šçµæ§‹"""
    layer: str
    files_processed: int
    changes_made: int
    success: bool
    details: Dict[str, Any]
    timestamp: str


class MachineNativeConverter:
    """MachineNativeOps æ ¸å¿ƒè½‰æ›å™¨"""
    
    def __init__(self, config_path: Optional[str] = None):
        """åˆå§‹åŒ–è½‰æ›å™¨"""
        self.config = self._load_config(config_path)
        self.mcp_rules = self._load_mcp_rules()
        self.governance_rules = self._load_governance_rules()
        self.conversion_rules = self._build_conversion_rules()
        self.ssot_registry = {}
        
        logger.info("MachineNativeOps è½‰æ›å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _load_config(self, config_path: Optional[str]) -> Dict[str, Any]:
        """åŠ è¼‰é…ç½®æ–‡ä»¶"""
        default_path = Path(__file__).parent.parent / "config" / "conversion.yaml"
        config_file = Path(config_path) if config_path else default_path
        
        if not config_file.exists():
            logger.warning(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}ï¼Œä½¿ç”¨é»˜èªé…ç½®")
            return self._get_default_config()
        
        try:
            with open(config_file, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
                logger.info(f"æˆåŠŸåŠ è¼‰é…ç½®: {config_file}")
                return config
        except Exception as e:
            logger.error(f"åŠ è¼‰é…ç½®å¤±æ•—: {e}")
            return self._get_default_config()
    
    def _load_mcp_rules(self) -> Dict[str, Any]:
        """åŠ è¼‰ MCP è¦å‰‡"""
        mcp_rules_path = Path(__file__).parent.parent / "config" / "mcp-rules.yaml"
        
        if not mcp_rules_path.exists():
            logger.warning("MCP è¦å‰‡æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜èªè¦å‰‡")
            return {}
        
        try:
            with open(mcp_rules_path, 'r', encoding='utf-8') as f:
                rules = yaml.safe_load(f)
                logger.info("æˆåŠŸåŠ è¼‰ MCP è¦å‰‡")
                return rules
        except Exception as e:
            logger.error(f"åŠ è¼‰ MCP è¦å‰‡å¤±æ•—: {e}")
            return {}
    
    def _load_governance_rules(self) -> Dict[str, Any]:
        """åŠ è¼‰æ²»ç†è¦å‰‡"""
        governance_path = Path(__file__).parent.parent / "config" / "governance.yaml"
        
        if not governance_path.exists():
            logger.warning("æ²»ç†è¦å‰‡æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜èªè¦å‰‡")
            return {}
        
        try:
            with open(governance_path, 'r', encoding='utf-8') as f:
                rules = yaml.safe_load(f)
                logger.info("æˆåŠŸåŠ è¼‰æ²»ç†è¦å‰‡")
                return rules
        except Exception as e:
            logger.error(f"åŠ è¼‰æ²»ç†è¦å‰‡å¤±æ•—: {e}")
            return {}
    
    def _get_default_config(self) -> Dict[str, Any]:
        """ç²å–é»˜èªé…ç½®"""
        return {
            "enterprise": {
                "prefix": "machine-native",
                "namespace": "mnops",
                "domain": "machinenativeops.com"
            },
            "file_types": {
                "source_code": [".py", ".js", ".ts", ".java", ".go"],
                "config_files": [".json", ".yaml", ".yml"],
                "documentation": [".md", ".rst", ".txt"]
            }
        }
    
    def _build_conversion_rules(self) -> Dict[str, List[ConversionRule]]:
        """æ§‹å»ºè½‰æ›è¦å‰‡"""
        rules = {
            "namespace": self._build_namespace_rules(),
            "dependency": self._build_dependency_rules(),
            "reference": self._build_reference_rules(),
            "structure": self._build_structure_rules(),
            "semantic": self._build_semantic_rules(),
            "governance": self._build_governance_rules()
        }
        
        logger.info(f"æ§‹å»ºäº† {sum(len(r) for r in rules.values())} æ¢è½‰æ›è¦å‰‡")
        return rules
    
    def _build_namespace_rules(self) -> List[ConversionRule]:
        """æ§‹å»ºå‘½åç©ºé–“è¦å‰‡"""
        return [
            ConversionRule(
                name="class_naming",
                pattern=r'class\s+([A-Z][a-zA-Z0-9_]*)',
                replacement=r'class MachineNative\1',
                file_types=["source_code"],
                context="class_names",
                priority=100,
                description="é¡åæ·»åŠ  MachineNative å‰ç¶´"
            ),
            ConversionRule(
                name="method_naming",
                pattern=r'def\s+([a-z][a-zA-Z0-9_]*)\s*\(',
                replacement=r'def mnops_\1(',
                file_types=["source_code"],
                context="method_names",
                priority=95,
                description="æ–¹æ³•åæ·»åŠ  mnops_ å‰ç¶´"
            ),
            ConversionRule(
                name="constant_naming",
                pattern=r'\b([A-Z][A-Z0-9_]+)\s*=',
                replacement=r'MNOPS_\1 =',
                file_types=["source_code"],
                context="constant_names",
                priority=90,
                description="å¸¸é‡åæ·»åŠ  MNOPS_ å‰ç¶´"
            )
        ]
    
    def _build_dependency_rules(self) -> List[ConversionRule]:
        """æ§‹å»ºä¾è³´è¦å‰‡ - v2.0 å¢å¼·ç‰ˆï¼šæ”¯æ´è£¸å°å…¥å’Œå­—ä¸²å°å…¥"""
        dependency_mapping = self.config.get("dependency_mapping", {})
        rules = []
        
        for lang, mappings in dependency_mapping.items():
            for old_dep, new_dep in mappings.items():
                # è½‰ç¾©ç‰¹æ®Šå­—ç¬¦
                escaped_old = re.escape(old_dep)
                
                # è¦å‰‡ 1: å­—ä¸²å½¢å¼çš„ä¾è³´ (å¦‚ "django", 'flask')
                rules.append(ConversionRule(
                    name=f"dependency_{lang}_{old_dep}_string",
                    pattern=f'["\']({escaped_old})["\']',
                    replacement=f'"{new_dep}"',
                    file_types=["source_code", "config_files"],
                    context=f"{lang}_dependencies_string",
                    priority=90,
                    description=f"æ›¿æ›å­—ä¸²ä¾è³´ {old_dep} ç‚º {new_dep}"
                ))
                
                # è¦å‰‡ 2: Python è£¸å°å…¥ (import django, from flask import)
                if lang == "python":
                    module_name = new_dep.replace("-", "_")
                    # æ”¯æ´æ˜Ÿè™Ÿèˆ‡é€—è™Ÿåˆ†éš”çš„åŒ¯å…¥é …ç›®ï¼ˆå«æ‹¬è™Ÿå½¢å¼ï¼‰
                    from_import_targets = r'(?:\((?:[a-zA-Z_]\w*(?:\s*,\s*[a-zA-Z_]\w*)*|\*)\s*\)|(?:[a-zA-Z_]\w*(?:\s*,\s*[a-zA-Z_]\w*)*|\*))'
                    # import django
                    rules.append(ConversionRule(
                        name=f"dependency_{lang}_{old_dep}_bare_import",
                        pattern=f'\\bimport\\s+{escaped_old}\\b',
                        replacement=f'import {module_name}  # namespace-mcp: {new_dep}',
                        file_types=["source_code"],
                        context=f"{lang}_dependencies_bare",
                        priority=95,
                        description=f"æ›¿æ›è£¸å°å…¥ import {old_dep}"
                    ))
                    
                    # from django import
                    rules.append(ConversionRule(
                        name=f"dependency_{lang}_{old_dep}_from_import",
                        pattern=f'\\bfrom\\s+{escaped_old}\\s+import\\s+({from_import_targets})',
                        replacement=f'from {module_name} import \\1  # namespace-mcp: {new_dep}',
                        file_types=["source_code"],
                        context=f"{lang}_dependencies_from",
                        priority=95,
                        description=f"æ›¿æ› from {old_dep} import"
                    ))
                
                # è¦å‰‡ 3: JavaScript require/import
                if lang == "javascript":
                    # require('express')
                    rules.append(ConversionRule(
                        name=f"dependency_{lang}_{old_dep}_require",
                        pattern=f'require\\(["\']({escaped_old})["\']\\)',
                        replacement=f'require("{new_dep}")',
                        file_types=["source_code"],
                        context=f"{lang}_dependencies_require",
                        priority=95,
                        description=f"æ›¿æ› require('{old_dep}')"
                    ))
                    
                    # import express from 'express'
                    rules.append(ConversionRule(
                        name=f"dependency_{lang}_{old_dep}_import",
                        pattern=f'from\\s+["\']({escaped_old})["\']',
                        replacement=f'from "{new_dep}"',
                        file_types=["source_code"],
                        context=f"{lang}_dependencies_import",
                        priority=95,
                        description=f"æ›¿æ› from '{old_dep}'"
                    ))
        
        return rules
    
    def _build_reference_rules(self) -> List[ConversionRule]:
        """æ§‹å»ºå¼•ç”¨è¦å‰‡"""
        return [
            ConversionRule(
                name="python_import",
                pattern=r'from\s+([.\w]+)\s+import',
                replacement=r'from machine_native.\1 import',
                file_types=["source_code"],
                context="python_imports",
                priority=80,
                description="Python å°å…¥èªå¥æ¨™æº–åŒ–"
            ),
            ConversionRule(
                name="javascript_require",
                pattern=r'require\(["\']([^"\']+)["\']\)',
                replacement=r'require("machine-native/\1")',
                file_types=["source_code"],
                context="javascript_requires",
                priority=75,
                description="JavaScript require èªå¥æ¨™æº–åŒ–"
            )
        ]
    
    def _build_structure_rules(self) -> List[ConversionRule]:
        """æ§‹å»ºçµæ§‹è¦å‰‡"""
        return [
            ConversionRule(
                name="source_directory",
                pattern=r'^src/',
                replacement='lib/',
                file_types=["all"],
                context="directory_structure",
                priority=70,
                description="æºä»£ç¢¼ç›®éŒ„é‡å‘½å"
            ),
            ConversionRule(
                name="docs_directory",
                pattern=r'^docs/',
                replacement='documentation/',
                file_types=["all"],
                context="directory_structure",
                priority=65,
                description="æ–‡æª”ç›®éŒ„é‡å‘½å"
            )
        ]
    
    def _build_semantic_rules(self) -> List[ConversionRule]:
        """æ§‹å»ºèªæ„è¦å‰‡"""
        return [
            ConversionRule(
                name="semantic_naming",
                pattern=r'\b(process|handle|execute)([A-Z][a-zA-Z0-9]*)',
                replacement=r'mnops_\1_\2',
                file_types=["source_code"],
                context="semantic_methods",
                priority=60,
                description="èªæ„æ–¹æ³•åæ¨™æº–åŒ–"
            )
        ]
    
    def _build_governance_rules(self) -> List[ConversionRule]:
        """æ§‹å»ºæ²»ç†è¦å‰‡"""
        license_header = self.governance_rules.get("license", {}).get("header_template", "")
        
        return [
            ConversionRule(
                name="license_conversion",
                pattern=r'license\s*[:=]\s*["\']([^"\']+)["\']',
                replacement='license: "MachineNativeOps Enterprise License v1.0"',
                file_types=["config_files"],
                context="license_update",
                priority=100,
                description="è¨±å¯è­‰è½‰æ›"
            ),
            ConversionRule(
                name="copyright_header",
                pattern=r'^(#!/[^\n]*\n)?',
                replacement=f'\\1{license_header}\n\n',
                file_types=["source_code"],
                context="copyright_header",
                priority=95,
                description="æ·»åŠ ç‰ˆæ¬Šé ­"
            )
        ]
    
    def convert_project(self, source_path: str, target_path: str) -> Dict[str, ConversionResult]:
        """åŸ·è¡Œå°ˆæ¡ˆè½‰æ›"""
        logger.info(f"é–‹å§‹è½‰æ›å°ˆæ¡ˆ: {source_path} â†’ {target_path}")
        
        source_dir = Path(source_path)
        target_dir = Path(target_path)
        
        if not source_dir.exists():
            raise ValueError(f"æºå°ˆæ¡ˆè·¯å¾‘ä¸å­˜åœ¨: {source_path}")
        
        # å‰µå»ºç›®æ¨™ç›®éŒ„
        target_dir.mkdir(parents=True, exist_ok=True)
        
        # è¤‡è£½å°ˆæ¡ˆçµæ§‹
        self._copy_project_structure(source_dir, target_dir)
        
        # åŸ·è¡Œå…­å±¤è½‰æ›
        results = {}
        layers = ["namespace", "dependency", "reference", "structure", "semantic", "governance"]
        
        for layer in layers:
            logger.info(f"åŸ·è¡Œ {layer} å±¤è½‰æ›...")
            results[layer] = self._apply_layer_conversion(layer, target_dir)
        
        # ç”Ÿæˆè½‰æ›å ±å‘Š
        self._generate_conversion_report(results, target_dir)
        
        logger.info("å°ˆæ¡ˆè½‰æ›å®Œæˆ")
        return results
    
    def _copy_project_structure(self, source: Path, target: Path):
        """è¤‡è£½å°ˆæ¡ˆçµæ§‹"""
        import shutil
        
        if target.exists():
            shutil.rmtree(target)
        
        ignore_patterns = shutil.ignore_patterns(
            '.git', '.svn', '.DS_Store', '__pycache__', 'node_modules',
            '*.pyc', '*.class', '*.jar', '.idea', '.vscode'
        )
        
        shutil.copytree(source, target, ignore=ignore_patterns)
        logger.info(f"å°ˆæ¡ˆçµæ§‹å·²è¤‡è£½: {source} â†’ {target}")
    
    def _apply_layer_conversion(self, layer: str, target_dir: Path) -> ConversionResult:
        """æ‡‰ç”¨å±¤ç´šè½‰æ›"""
        rules = self.conversion_rules.get(layer, [])
        files_processed = 0
        changes_made = 0
        details = {}
        
        for rule in rules:
            try:
                rule_changes = self._apply_conversion_rule(rule, target_dir)
                changes_made += rule_changes
                details[rule.context] = rule_changes
                logger.debug(f"è¦å‰‡ {rule.name} æ‡‰ç”¨å®Œæˆï¼Œè®Šæ›´æ•¸: {rule_changes}")
            except Exception as e:
                logger.error(f"è¦å‰‡ {rule.name} æ‡‰ç”¨å¤±æ•—: {e}")
                details[rule.context] = {"error": str(e)}
        
        # çµ±è¨ˆè™•ç†çš„æ–‡ä»¶æ•¸
        for root, _, files in os.walk(target_dir):
            files_processed += len(files)
        
        return ConversionResult(
            layer=layer,
            files_processed=files_processed,
            changes_made=changes_made,
            success=changes_made > 0,
            details=details,
            timestamp=datetime.now().isoformat()
        )
    
    def _apply_conversion_rule(self, rule: ConversionRule, target_dir: Path) -> int:
        """æ‡‰ç”¨å–®å€‹è½‰æ›è¦å‰‡"""
        changes_made = 0
        
        for root, _, files in os.walk(target_dir):
            for file in files:
                file_path = Path(root) / file
                
                # æª¢æŸ¥æ–‡ä»¶é¡å‹
                if not self._should_process_file(file_path, rule.file_types):
                    continue
                
                try:
                    # è®€å–æ–‡ä»¶å…§å®¹
                    content = file_path.read_text(encoding='utf-8')
                    
                    # æ‡‰ç”¨è½‰æ›è¦å‰‡
                    new_content, changes = self._apply_pattern_replacement(
                        content, rule.pattern, rule.replacement
                    )
                    
                    if changes > 0:
                        # å¯«å…¥è½‰æ›å¾Œå…§å®¹
                        file_path.write_text(new_content, encoding='utf-8')
                        changes_made += changes
                        
                        # è¨˜éŒ„åˆ° SSOT
                        self._register_ssot_change(
                            file_path, rule.context, changes, rule.priority / 100
                        )
                        
                        logger.debug(f"æ–‡ä»¶ {file_path} è½‰æ›å®Œæˆï¼Œè®Šæ›´æ•¸: {changes}")
                
                except Exception as e:
                    logger.warning(f"è™•ç†æ–‡ä»¶å¤±æ•— {file_path}: {e}")
                    continue
        
        return changes_made
    
    def _should_process_file(self, file_path: Path, allowed_types: List[str]) -> bool:
        """æª¢æŸ¥æ˜¯å¦æ‡‰è©²è™•ç†æ–‡ä»¶"""
        if "all" in allowed_types:
            return True
        
        file_extension = file_path.suffix.lower()
        file_type_mapping = self.config.get("file_types", {})
        
        for file_type, extensions in file_type_mapping.items():
            if file_type in allowed_types and file_extension in extensions:
                return True
        
        return False
    
    def _apply_pattern_replacement(self, content: str, pattern: str, replacement: str) -> Tuple[str, int]:
        """æ‡‰ç”¨æ¨¡å¼æ›¿æ›"""
        new_content, count = re.subn(pattern, replacement, content, flags=re.MULTILINE)
        return new_content, count
    
    def _register_ssot_change(self, file_path: Path, context: str, changes: int, confidence: float):
        """è¨»å†Š SSOT è®Šæ›´"""
        file_key = str(file_path)
        if file_key not in self.ssot_registry:
            self.ssot_registry[file_key] = []
        
        self.ssot_registry[file_key].append({
            "context": context,
            "changes": changes,
            "confidence": confidence,
            "timestamp": datetime.now().isoformat(),
            "signature": self._generate_change_signature(file_path, context)
        })
    
    def _generate_change_signature(self, file_path: Path, context: str) -> str:
        """ç”Ÿæˆè®Šæ›´ç°½å"""
        data = f"{file_path}:{context}:{datetime.now().timestamp()}"
        return hashlib.sha3_512(data.encode()).hexdigest()
    
    def _generate_conversion_report(self, results: Dict[str, ConversionResult], target_dir: Path):
        """ç”Ÿæˆè½‰æ›å ±å‘Š"""
        report = {
            "version": "1.0.0",
            "timestamp": datetime.now().isoformat(),
            "source_project": str(target_dir),
            "slsa_level": "L3+",
            "conversion_results": {},
            "summary": {
                "total_files": sum(r.files_processed for r in results.values()),
                "total_changes": sum(r.changes_made for r in results.values()),
                "successful_layers": sum(1 for r in results.values() if r.success),
                "total_layers": len(results)
            },
            "ssot_hash": self._generate_ssot_hash()
        }
        
        for layer, result in results.items():
            report["conversion_results"][layer] = asdict(result)
        
        # å¯«å…¥ JSON å ±å‘Š
        report_path = target_dir / "conversion-report.json"
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        # ç”Ÿæˆ Markdown å ±å‘Š
        self._generate_markdown_report(report, target_dir)
        
        logger.info(f"è½‰æ›å ±å‘Šå·²ç”Ÿæˆ: {report_path}")
    
    def _generate_ssot_hash(self) -> str:
        """ç”Ÿæˆ SSOT å“ˆå¸Œ"""
        ssot_data = json.dumps(self.ssot_registry, sort_keys=True)
        return hashlib.sha3_512(ssot_data.encode()).hexdigest()
    
    def _generate_markdown_report(self, report: Dict[str, Any], target_dir: Path):
        """ç”Ÿæˆ Markdown å ±å‘Š"""
        md_content = [
            "# MachineNativeOps å°ˆæ¡ˆè½‰æ›å ±å‘Š",
            "",
            "## ğŸ“Š è½‰æ›æ‘˜è¦",
            "",
            f"- **è½‰æ›ç‰ˆæœ¬**: `{report['version']}`",
            f"- **è½‰æ›æ™‚é–“**: `{report['timestamp']}`",
            f"- **ç›®æ¨™å°ˆæ¡ˆ**: `{report['source_project']}`",
            f"- **SLSA ç­‰ç´š**: `{report['slsa_level']}`",
            f"- **ç¸½æ–‡ä»¶æ•¸**: `{report['summary']['total_files']}`",
            f"- **ç¸½è®Šæ›´æ•¸**: `{report['summary']['total_changes']}`",
            f"- **æˆåŠŸå±¤ç´š**: `{report['summary']['successful_layers']}/{report['summary']['total_layers']}`",
            f"- **SSOT å“ˆå¸Œ**: `{report['ssot_hash'][:32]}...`",
            "",
            "## ğŸ¯ å±¤ç´šè½‰æ›çµæœ",
            "",
            "| æ²»ç†å±¤ç´š | æ–‡ä»¶æ•¸ | è®Šæ›´æ•¸ | ç‹€æ…‹ |",
            "|----------|--------|--------|------|"
        ]
        
        for layer, result in report["conversion_results"].items():
            status_icon = "âœ…" if result["success"] else "âš ï¸"
            md_content.append(
                f"| {layer} | {result['files_processed']} | {result['changes_made']} | {status_icon} |"
            )
        
        md_content.extend([
            "",
            "## ğŸ” è©³ç´°çµæœ",
            ""
        ])
        
        for layer, result in report["conversion_results"].items():
            md_content.append(f"### {layer.capitalize()} å±¤")
            md_content.append("")
            
            for context, details in result["details"].items():
                if isinstance(details, dict) and "error" in details:
                    md_content.append(f"- **{context}**: âŒ {details['error']}")
                else:
                    md_content.append(f"- **{context}**: {details} è™•è®Šæ›´")
            md_content.append("")
        
        md_content.extend([
            "## ğŸ” å®‰å…¨åˆè¦",
            "",
            f"- **SSOT å®Œæ•´æ€§**: `{report['ssot_hash'][:64]}...`",
            "- **å¯©è¨ˆè·Ÿè¸ª**: æ‰€æœ‰è®Šæ›´å·²è¨˜éŒ„åˆ° SSOT",
            f"- **åˆè¦ç­‰ç´š**: `{report['slsa_level']}`",
            "",
            "---",
            f"*ç”Ÿæˆæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*"
        ])
        
        report_path = target_dir / "CONVERSION-REPORT.md"
        report_path.write_text("\n".join(md_content), encoding='utf-8')
        
        logger.info(f"Markdown å ±å‘Šå·²ç”Ÿæˆ: {report_path}")


def main():
    """ä¸»å‡½æ•¸"""
    import argparse
    
    parser = argparse.ArgumentParser(description='MachineNativeOps å°ˆæ¡ˆè½‰æ›å™¨')
    parser.add_argument('source', help='æºå°ˆæ¡ˆè·¯å¾‘')
    parser.add_argument('target', help='ç›®æ¨™å°ˆæ¡ˆè·¯å¾‘')
    parser.add_argument('--config', '-c', help='é…ç½®æ–‡ä»¶è·¯å¾‘')
    parser.add_argument('--verbose', '-v', action='store_true', help='è©³ç´°è¼¸å‡º')
    
    args = parser.parse_args()
    
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    try:
        converter = MachineNativeConverter(args.config)
        results = converter.convert_project(args.source, args.target)
        
        total_changes = sum(r.changes_made for r in results.values())
        successful_layers = sum(1 for r in results.values() if r.success)
        
        print(f"\nâœ… è½‰æ›å®Œæˆ!")
        print(f"ğŸ“Š ç¸½è®Šæ›´æ•¸: {total_changes}")
        print(f"ğŸ¯ æˆåŠŸå±¤ç´š: {successful_layers}/{len(results)}")
        print(f"ğŸ“ å ±å‘Šæ–‡ä»¶: {args.target}/CONVERSION-REPORT.md")
        
    except Exception as e:
        logger.error(f"è½‰æ›éç¨‹å‡ºéŒ¯: {e}")
        print(f"âŒ è½‰æ›å¤±æ•—: {e}")
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main())
