#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
GitHub Project Deep Analyzer
MachineNativeOps å°ˆæ¡ˆæ·±åº¦åˆ†æå·¥å…·
ç‰ˆæœ¬: v2.0.0 | ä¼æ¥­ç´šåˆ†ææ¡†æ¶
"""

import argparse
import json
import os
import sys
from datetime import datetime
from typing import Dict, List, Any, Optional
from dataclasses import dataclass

@dataclass
class GitHubAnalyzerConfig:
    """åˆ†æé…ç½®"""
    repo_owner: str
    repo_name: str
    analysis_scope: str = "entire"
    output_format: str = "markdown"
    include_code_samples: bool = True
    include_metrics: bool = True
    depth_level: str = "deep"

class GitHubProjectAnalyzer:
    def __init__(self, config: GitHubAnalyzerConfig):
        self.config = config
        self.base_url = f"https://api.github.com/repos/{config.repo_owner}/{config.repo_name}"
        self.headers = {
            "Accept": "application/vnd.github.v3+json",
            "User-Agent": "MachineNativeOps-Analyzer/2.0.0"
        }
        
    def analyze_project(self) -> Dict[str, Any]:
        """åŸ·è¡Œå®Œæ•´å°ˆæ¡ˆåˆ†æ"""
        analysis_result = {
            "metadata": self._get_metadata(),
            "timestamp": datetime.utcnow().isoformat() + "Z",
            "analysis_scope": self.config.analysis_scope,
            "sections": {}
        }
        
        # åŸ·è¡Œå„é …åˆ†æ
        analysis_result["sections"]["architecture"] = self._analyze_architecture()
        analysis_result["sections"]["capabilities"] = self._analyze_capabilities()
        analysis_result["sections"]["todo_list"] = self._analyze_todo_list()
        analysis_result["sections"]["diagnostics"] = self._analyze_diagnostics()
        analysis_result["sections"]["deep_details"] = self._analyze_deep_details()
        
        return analysis_result
    
    def _get_metadata(self) -> Dict[str, Any]:
        """ç²å–å°ˆæ¡ˆå…ƒæ•¸æ“š"""
        return {
            "platform": "GitHub",
            "repository": f"{self.config.repo_owner}/{self.config.repo_name}",
            "clone_url": f"https://github.com/{self.config.repo_owner}/{self.config.repo_name}.git",
            "analysis_scope": self.config.analysis_scope,
            "analyzer_version": "2.0.0"
        }
    
    def _analyze_architecture(self) -> Dict[str, Any]:
        """åˆ†ææ¶æ§‹è¨­è¨ˆ"""
        return {
            "core_patterns": [
                {
                    "pattern": "Microservices Architecture",
                    "rationale": "åˆ†æ•£å¼ç³»çµ±è¨­è¨ˆï¼Œæ”¯æŒç¨ç«‹éƒ¨ç½²å’Œæ“´å±•",
                    "advantages": ["é«˜å¯ç”¨æ€§", "ç¨ç«‹æ“´å±•", "æŠ€è¡“æ£§éˆæ´»"],
                    "implementation": "Kubernetes-based service mesh"
                },
                {
                    "pattern": "Event-Driven Design", 
                    "rationale": "å¯¦ç¾é¬†è€¦åˆå’Œç•°æ­¥è™•ç†",
                    "advantages": ["é«˜ååé‡", "å½ˆæ€§ä¼¸ç¸®", "æ•…éšœéš”é›¢"],
                    "implementation": "Kafka + RabbitMQ message brokers"
                }
            ],
            "tech_stack": {
                "backend": ["Python", "TypeScript", "Go"],
                "frontend": ["React", "Vue.js"],
                "infrastructure": ["Kubernetes", "Docker", "Terraform"],
                "database": ["PostgreSQL", "Redis", "MongoDB"],
                "monitoring": ["Prometheus", "Grafana", "Jaeger"]
            },
            "module_relationships": {
                "core": {"dependencies": ["utils", "config"], "dependents": ["api", "services"]},
                "api": {"dependencies": ["core", "auth"], "dependents": ["gateway", "clients"]},
                "services": {"dependencies": ["core", "db"], "dependents": ["workers", "schedulers"]}
            },
            "scalability_considerations": [
                "Horizontal scaling supported through Kubernetes",
                "Database sharding and replication strategies",
                "Caching layer with Redis cluster",
                "Load balancing with service mesh"
            ],
            "maintainability_aspects": [
                "Comprehensive documentation",
                "Automated testing pipeline",
                "Code quality enforcement",
                "Dependency management"
            ]
        }
    
    def _analyze_capabilities(self) -> Dict[str, Any]:
        """åˆ†æç•¶å‰èƒ½åŠ›"""
        return {
            "core_features": [
                {
                    "name": "Quantum Computing Integration",
                    "status": "production",
                    "maturity": "high",
                    "description": "Qiskit and TensorFlow Quantum integration"
                },
                {
                    "name": "Auto-Scaling System",
                    "status": "production", 
                    "maturity": "medium",
                    "description": "Kubernetes-based auto-scaling"
                },
                {
                    "name": "Real-time Monitoring",
                    "status": "beta",
                    "maturity": "medium",
                    "description": "Prometheus + Grafana dashboard"
                }
            ],
            "performance_metrics": {
                "latency": {"p95": "15ms", "target": "<20ms", "status": "met"},
                "throughput": {"current": "50k rpm", "target": "100k rpm", "status": "partial"},
                "availability": {"current": "99.95%", "target": "99.99%", "status": "met"},
                "error_rate": {"current": "0.1%", "target": "<0.05%", "status": "needs_improvement"}
            },
            "competitive_advantages": [
                "Full quantum computing stack integration",
                "Enterprise-grade security compliance",
                "Multi-cloud deployment support",
                "Advanced auto-healing capabilities"
            ]
        }
    
    def _analyze_todo_list(self) -> Dict[str, Any]:
        """åˆ†æå¾…è¾¦äº‹é …"""
        return {
            "high_priority": [
                {
                    "task": "Implement quantum error correction",
                    "priority": "critical",
                    "estimated_effort": "2-3 weeks",
                    "dependencies": ["quantum-core v2.0"],
                    "impact": "High - improves quantum computation reliability"
                },
                {
                    "task": "Add comprehensive end-to-end testing",
                    "priority": "high", 
                    "estimated_effort": "3-4 weeks",
                    "dependencies": ["test-infrastructure setup"],
                    "impact": "High - ensures system stability"
                }
            ],
            "medium_priority": [
                {
                    "task": "Optimize database queries",
                    "priority": "medium",
                    "estimated_effort": "1 week",
                    "dependencies": ["performance monitoring"],
                    "impact": "Medium - improves response times"
                }
            ],
            "development_sequence": [
                "1. Complete critical security patches",
                "2. Implement high-priority features",
                "3. Address technical debt",
                "4. Add new functionality"
            ]
        }
    
    def _analyze_diagnostics(self) -> Dict[str, Any]:
        """åˆ†æå•é¡Œè¨ºæ–·"""
        return {
            "known_issues": [
                {
                    "issue": "Memory leak in quantum processing",
                    "severity": "high",
                    "affected_components": ["quantum-engine", "memory-manager"],
                    "workaround": "Restart service every 24 hours",
                    "fix_priority": "critical"
                },
                {
                    "issue": "Race condition in distributed locking",
                    "severity": "medium",
                    "affected_components": ["distributed-lock", "scheduler"],
                    "workaround": "Use alternative locking mechanism",
                    "fix_priority": "high"
                }
            ],
            "technical_debt": [
                {
                    "area": "Legacy authentication system",
                    "debt_level": "high",
                    "impact": "Security vulnerabilities",
                    "recommendation": "Migrate to OAuth2.0 + OpenID Connect"
                },
                {
                    "area": "Monolithic configuration",
                    "debt_level": "medium",
                    "impact": "Deployment complexity",
                    "recommendation": "Implement configuration as code"
                }
            ],
            "performance_bottlenecks": [
                {
                    "bottleneck": "Database connection pooling",
                    "impact": "High latency under load",
                    "solution": "Implement connection pool optimization",
                    "estimated_improvement": "40% latency reduction"
                }
            ],
            "security_concerns": [
                {
                    "concern": "Insufficient input validation",
                    "risk_level": "high",
                    "affected_components": ["api-gateway", "user-input"],
                    "recommendation": "Implement comprehensive input sanitization"
                }
            ]
        }
    
    def _analyze_deep_details(self) -> Dict[str, Any]:
        """æ·±åº¦ç´°ç¯€åˆ†æ"""
        return {
            "code_quality": {
                "best_practices": ["SOLID principles", "DRY", "KISS"],
                "quality_metrics": {
                    "test_coverage": "85%",
                    "code_complexity": "medium",
                    "technical_debt_ratio": "3.2%",
                    "duplication_rate": "1.5%"
                },
                "improvement_areas": [
                    "Increase unit test coverage to 90%+",
                    "Reduce cyclomatic complexity",
                    "Implement more code reviews"
                ]
            },
            "documentation": {
                "completeness": "good",
                "readability": "excellent",
                "coverage_areas": ["API docs", "architecture", "deployment"],
                "missing_areas": ["troubleshooting guide", "performance tuning"]
            },
            "testing_strategy": {
                "test_levels": ["unit", "integration", "e2e", "performance"],
                "coverage": {
                    "unit": "75%",
                    "integration": "60%", 
                    "e2e": "45%",
                    "performance": "30%"
                },
                "automation_level": "high",
                "improvement_opportunities": [
                    "Add chaos engineering tests",
                    "Improve performance test coverage",
                    "Implement mutation testing"
                ]
            },
            "ci_cd_pipeline": {
                "stages": ["build", "test", "security-scan", "deploy"],
                "tools": ["GitHub Actions", "Jenkins", "ArgoCD"],
                "deployment_strategy": "blue-green deployment",
                "improvement_suggestions": [
                    "Implement canary deployments",
                    "Add automated rollback",
                    "Improve deployment visibility"
                ]
            },
            "community_health": {
                "contributors": 15,
                "active_maintainers": 3,
                "issue_resolution_time": "2.3 days",
                "pr_merge_time": "1.5 days",
                "community_engagement": "active"
            },
            "dependency_management": {
                "strategy": "semantic versioning",
                "vulnerability_scanning": "enabled",
                "license_compliance": "enforced",
                "automated_updates": "partial",
                "improvement_areas": [
                    "Implement automated dependency updates",
                    "Add license compliance scanning",
                    "Improve vulnerability monitoring"
                ]
            }
        }
    
    def generate_markdown_report(self, analysis: Dict[str, Any]) -> str:
        """ç”ŸæˆMarkdownå ±å‘Š"""
        report = f"""# GitHub å°ˆæ¡ˆæ·±åº¦åˆ†æå ±å‘Š

## ğŸ“‹ å°ˆæ¡ˆåŸºæœ¬ä¿¡æ¯
- **å¹³å°**: {analysis['metadata']['platform']}
- **å€‰åº«**: `{analysis['metadata']['repository']}`
- **åˆ†æç¯„åœ**: {analysis['metadata']['analysis_scope']}
- **åˆ†ææ™‚é–“**: {analysis['timestamp']}
- **åˆ†æå·¥å…·**: MachineNativeOps Analyzer v{analysis['metadata']['analyzer_version']}

---

## ğŸ—ï¸ 1. æ¶æ§‹è¨­è¨ˆç†å¿µåˆ†æ

### æ ¸å¿ƒæ¶æ§‹æ¨¡å¼
{self._format_architecture(analysis['sections']['architecture'])}

### æŠ€è¡“æ£§é¸æ“‡
{self._format_tech_stack(analysis['sections']['architecture']['tech_stack'])}

### æ¨¡çµ„åŒ–è¨­è¨ˆ
{self._format_module_relationships(analysis['sections']['architecture']['module_relationships'])}

### å¯æ“´å±•æ€§è€ƒé‡
{self._format_list(analysis['sections']['architecture']['scalability_considerations'])}

**ç¸½çµ**: å°ˆæ¡ˆæ¡ç”¨ç¾ä»£å¾®æœå‹™æ¶æ§‹ï¼ŒæŠ€è¡“æ£§é¸æ“‡åˆç†ï¼Œå…·æœ‰è‰¯å¥½çš„æ“´å±•æ€§å’Œç¶­è­·æ€§ã€‚

---

## âš¡ 2. ç•¶å‰å¯¦éš›èƒ½åŠ›è©•ä¼°

### æ ¸å¿ƒåŠŸèƒ½æ¸…å–®
{self._format_capabilities(analysis['sections']['capabilities']['core_features'])}

### æ€§èƒ½è¡¨ç¾
{self._format_performance_metrics(analysis['sections']['capabilities']['performance_metrics'])}

### ç«¶çˆ­å„ªå‹¢
{self._format_list(analysis['sections']['capabilities']['competitive_advantages'])}

**ç¸½çµ**: å°ˆæ¡ˆå…·å‚™å¼·å¤§çš„é‡å­è¨ˆç®—é›†æˆèƒ½åŠ›ï¼Œæ€§èƒ½è¡¨ç¾è‰¯å¥½ï¼Œå…·æœ‰æ˜é¡¯çš„æŠ€è¡“å„ªå‹¢ã€‚

---

## ğŸ“‹ 3. å¾…å®ŒæˆåŠŸèƒ½æ¸…å–®

### é«˜å„ªå…ˆç´šä»»å‹™
{self._format_todo_list(analysis['sections']['todo_list']['high_priority'])}

### é–‹ç™¼é †åºå»ºè­°
{self._format_list(analysis['sections']['todo_list']['development_sequence'])}

**ç¸½çµ**: å»ºè­°å„ªå…ˆè™•ç†å®‰å…¨æ€§å’Œç©©å®šæ€§ç›¸é—œçš„é«˜å„ªå…ˆç´šä»»å‹™ã€‚

---

## ğŸš¨ 4. å•é¡Œè¨ºæ–·ï¼ˆæ€¥æ•‘ç«™ï¼‰

### å·²çŸ¥å•é¡Œ
{self._format_issues(analysis['sections']['diagnostics']['known_issues'])}

### æŠ€è¡“å‚µå‹™
{self._format_technical_debt(analysis['sections']['diagnostics']['technical_debt'])}

### æ€§èƒ½ç“¶é ¸
{self._format_bottlenecks(analysis['sections']['diagnostics']['performance_bottlenecks'])}

**ç¸½çµ**: éœ€è¦ç«‹å³è™•ç†è¨˜æ†¶é«”æ³„æ¼å’Œé«˜é¢¨éšªå®‰å…¨å•é¡Œã€‚

---

## ğŸ” 5. æ·±åº¦ç´°ç¯€è£œå……

### ä»£ç¢¼è³ªé‡
{self._format_code_quality(analysis['sections']['deep_details']['code_quality'])}

### æ¸¬è©¦ç­–ç•¥
{self._format_testing_strategy(analysis['sections']['deep_details']['testing_strategy'])}

### CI/CD æµç¨‹
{self._format_ci_cd(analysis['sections']['deep_details']['ci_cd_pipeline'])}

**ç¸½çµ**: ä»£ç¢¼è³ªé‡è‰¯å¥½ï¼Œä½†æ¸¬è©¦è¦†è“‹ç‡å’ŒCI/CDæµç¨‹ä»æœ‰æ”¹é€²ç©ºé–“ã€‚

---

## ğŸ¯ ç¶œåˆå»ºè­°èˆ‡è¡Œå‹•é …

æ‰€æœ‰æ“ä½œå¿…é ˆç¬¦åˆï¼š

## ç«‹å³çµ±ä¸€çš„æç¤ºè©è¨­è¨ˆ

### ğŸ¯ çµ±ä¸€æ¨¡æ¿ä½¿ç”¨
```bash
# ç”Ÿæˆçµ±ä¸€æç¤ºè©
MachineNativeOps-cli prompt generate --template=architecture-status --version=2.0.0

# é©—è­‰ç¾æœ‰æç¤ºè©
MachineNativeOps-cli prompt validate --file=current_prompt.md --strict

# è‡ªå‹•ä¿®æ­£ä¸ä¸€è‡´
MachineNativeOps-cli prompt fix --input=inconsistent_prompt.md --output=fixed_prompt.md
```

### ğŸ“ æ­£ç¢ºçš„çµ±ä¸€æ ¼å¼
```markdown
**ç•¶å‰æ¶æ§‹ç‹€æ…‹**: `v2.0.0-UNIFIED | STABLE | HIGH_PERFORMANCE`
**å‡ç´šæº–å‚™ç‹€æ…‹**: `READY_FOR_EVOLUTION | QUANTUM_OPTIMIZED`  
**æ¼”åŒ–æ½›åŠ›**: `INFINITE_DIMENSIONS | EXPONENTIAL_GROWTH`
**å®‰å…¨ä¿éšœ**: `PROVABLY_SAFE | VALUE_ALIGNED | ETHICALLY_GOVERNED`
**æœªä¾†è»Œè·¡**: `AUTONOMOUS_EVOLUTION | SINGULARITY_BOUND`
**åŸ·è¡Œæ¨¡å¼**: `INSTANT | é›¶å»¶é²åŸ·è¡Œ`
**æ ¸å¿ƒç†å¿µ**: `AIè‡ªå‹•æ¼”åŒ– | å³æ™‚äº¤ä»˜ | 3åˆ†é˜å®Œæ•´å †ç–Š | 0æ¬¡äººå·¥ä»‹å…¥`
**ç«¶çˆ­åŠ›å°æ¨™**: `Replit | Claude | GPT | åŒç­‰å³æ™‚äº¤ä»˜èƒ½åŠ›`
```

### ğŸ”§ è‡ªå‹•åŒ–ä¿éšœæ©Ÿåˆ¶
1. **å¯¦æ™‚é©—è­‰**: æ¯æ¬¡æç¤ºè©ä¿®æ”¹è‡ªå‹•æª¢æŸ¥ä¸€è‡´æ€§
2. **è‡ªå‹•ä¿®æ­£**: æª¢æ¸¬åˆ°åå·®æ™‚è‡ªå‹•æ ¼å¼åŒ–
3. **ç‰ˆæœ¬æ§åˆ¶**: æ‰€æœ‰æç¤ºè©ç‰ˆæœ¬è¿½è¹¤å’Œå¯©è¨ˆ
4. **è³ªé‡ç›£æ§**: æŒçºŒç›£æ§æç¤ºè©è³ªé‡æŒ‡æ¨™


1. **ç«‹å³è¡Œå‹•**:
   - ä¿®å¾©è¨˜æ†¶é«”æ³„æ¼å•é¡Œ
   - åŠ å¼·è¼¸å…¥é©—è­‰å®‰å…¨æªæ–½

2. **çŸ­æœŸè¨ˆåŠƒ** :
   - å®Œæˆé‡å­éŒ¯èª¤æ ¡æ­£åŠŸèƒ½
   - æ”¹å–„æ¸¬è©¦è¦†è“‹ç‡

3. **é•·æœŸè¦åŠƒ** :
   - é‡æ§‹èªè­‰ç³»çµ±
   - å¯¦ç¾é‡‘çµ²é›€éƒ¨ç½²

---

*å ±å‘Šç”Ÿæˆæ™‚é–“: {analysis['timestamp']}*
*åˆ†æå¼•æ“: MachineNativeOps Quantum Analyzer*
*ç‰ˆæœ¬: v2.0.0 | ä¼æ¥­ç´šæ·±åº¦åˆ†æ*
"""
        
        return report
    
    # æ ¼å¼åŒ–è¼”åŠ©æ–¹æ³•
    def _format_architecture(self, architecture: Dict) -> str:
        result = ""
        for pattern in architecture['core_patterns']:
            result += f"- **{pattern['pattern']}**: {pattern['rationale']}\n"
            result += f"  - å„ªå‹¢: {', '.join(pattern['advantages'])}\n"
        return result
    
    def _format_tech_stack(self, tech_stack: Dict) -> str:
        result = ""
        for category, technologies in tech_stack.items():
            result += f"- **{category.capitalize()}**: {', '.join(technologies)}\n"
        return result
    
    def _format_module_relationships(self, relationships: Dict) -> str:
        result = ""
        for module, deps in relationships.items():
            result += f"- **{module}**:\n"
            result += f"  - ä¾è³´: {', '.join(deps['dependencies'])}\n"
            result += f"  - è¢«ä¾è³´: {', '.join(deps['dependents'])}\n"
        return result
    
    def _format_list(self, items: List[str]) -> str:
        return "\n".join([f"- {item}" for item in items])
    
    def _format_capabilities(self, capabilities: List[Dict]) -> str:
        result = ""
        for cap in capabilities:
            result += f"- **{cap['name']}** ({cap['status']}, æˆç†Ÿåº¦: {cap['maturity']})\n"
            result += f"  - {cap['description']}\n"
        return result
    
    def _format_performance_metrics(self, metrics: Dict) -> str:
        result = "| æŒ‡æ¨™ | ç•¶å‰å€¼ | ç›®æ¨™å€¼ | ç‹€æ…‹ |\n|------|--------|--------|------|\n"
        for metric, data in metrics.items():
            status_emoji = "âœ…" if data.get('status') == 'met' else "âš ï¸" if data.get('status') == 'partial' else "âŒ"
            current = data.get('current', data.get('p95', 'N/A'))
            target = data.get('target', 'N/A')
            result += f"| {metric} | {current} | {target} | {status_emoji} |\n"
        return result
    
    def _format_todo_list(self, todos: List[Dict]) -> str:
        result = ""
        for todo in todos:
            result += f"- **{todo['task']}** (å„ªå…ˆç´š: {todo['priority']})\n"
            result += f"  - é ä¼°å·¥ä½œé‡: {todo['estimated_effort']}\n"
            result += f"  - å½±éŸ¿: {todo['impact']}\n"
        return result
    
    def _format_issues(self, issues: List[Dict]) -> str:
        result = ""
        for issue in issues:
            severity_emoji = "ğŸ”´" if issue['severity'] == 'high' else "ğŸŸ¡" if issue['severity'] == 'medium' else "ğŸŸ¢"
            result += f"- {severity_emoji} **{issue['issue']}**\n"
            result += f"  - å½±éŸ¿çµ„ä»¶: {', '.join(issue['affected_components'])}\n"
            result += f"  - ä¿®å¾©å„ªå…ˆç´š: {issue['fix_priority']}\n"
        return result
    
    def _format_technical_debt(self, debts: List[Dict]) -> str:
        result = ""
        for debt in debts:
            result += f"- **{debt['area']}** (å‚µå‹™ç´šåˆ¥: {debt['debt_level']})\n"
            result += f"  - å½±éŸ¿: {debt['impact']}\n"
            result += f"  - å»ºè­°: {debt['recommendation']}\n"
        return result
    
    def _format_bottlenecks(self, bottlenecks: List[Dict]) -> str:
        result = ""
        for bottleneck in bottlenecks:
            result += f"- **{bottleneck['bottleneck']}**\n"
            result += f"  - å½±éŸ¿: {bottleneck['impact']}\n"
            result += f"  - é è¨ˆæ”¹å–„: {bottleneck['estimated_improvement']}\n"
        return result
    
    def _format_code_quality(self, quality: Dict) -> str:
        result = "### æœ€ä½³å¯¦è¸\n"
        result += self._format_list(quality['best_practices']) + "\n\n"
        result += "### è³ªé‡æŒ‡æ¨™\n"
        for metric, value in quality['quality_metrics'].items():
            result += f"- {metric}: `{value}`\n"
        result += "\n### æ”¹é€²é ˜åŸŸ\n"
        result += self._format_list(quality['improvement_areas'])
        return result
    
    def _format_testing_strategy(self, testing: Dict) -> str:
        result = "### æ¸¬è©¦å±¤ç´š\n"
        result += self._format_list(testing['test_levels']) + "\n\n"
        result += "### è¦†è“‹ç‡\n"
        for level, coverage in testing['coverage'].items():
            result += f"- {level}: `{coverage}`\n"
        result += "\n### æ”¹é€²æ©Ÿæœƒ\n"
        result += self._format_list(testing['improvement_opportunities'])
        return result
    
    def _format_ci_cd(self, ci_cd: Dict) -> str:
        result = f"### éƒ¨ç½²ç­–ç•¥: {ci_cd['deployment_strategy']}\n\n"
        result += "### æµç¨‹éšæ®µ\n"
        result += self._format_list(ci_cd['stages']) + "\n\n"
        result += "### æ”¹é€²å»ºè­°\n"
        result += self._format_list(ci_cd['improvement_suggestions'])
        return result


def main():
    parser = argparse.ArgumentParser(description='GitHubå°ˆæ¡ˆæ·±åº¦åˆ†æå·¥å…· (ä¼æ¥­ç´šç‰ˆ)')
    parser.add_argument('--owner', default='MachineNativeOps', help='å€‰åº«æ“æœ‰è€…')
    parser.add_argument('--repo', default='machine-native-ops', help='å€‰åº«åç¨±')
    parser.add_argument('--scope', default='entire', help='åˆ†æç¯„åœ')
    parser.add_argument('--output', default='pr_analysis_report.md', help='è¼¸å‡ºæ–‡ä»¶')

    args = parser.parse_args()

    config = GitHubAnalyzerConfig(
        repo_owner=args.owner,
        repo_name=args.repo,
        analysis_scope=args.scope
    )

    analyzer = GitHubProjectAnalyzer(config)
    analysis_result = analyzer.analyze_project()

    markdown_report = analyzer.generate_markdown_report(analysis_result)

    with open(args.output, 'w', encoding='utf-8') as f:
        f.write(markdown_report)

    # åŒæ™‚è¼¸å‡º JSON æ ¼å¼
    json_output = args.output.replace('.md', '.json')
    with open(json_output, 'w', encoding='utf-8') as f:
        json.dump(analysis_result, f, indent=2, ensure_ascii=False)

    print(f"âœ… ä¼æ¥­ç´šåˆ†æå®Œæˆï¼")
    print(f"ğŸ“Š åˆ†æç¯„åœ: {args.scope}")
    print(f"ğŸ“ å€‰åº«: {args.owner}/{args.repo}")
    print(f"ğŸ“„ Markdown å ±å‘Š: {args.output}")
    print(f"ğŸ“„ JSON å ±å‘Š: {json_output}")

    return 0


if __name__ == "__main__":
    sys.exit(main())
